从经验看a[i].log.stat哈希完以后每个文件100M左右最合适
由于bid pid tid  增加的间隔很不一样，用mod的话，合适的mod值很难找。如果是连续的那用mod出来，
可以很好的控制块数，已经各个块的大小一致。



在v_start_all.sh脚本中
#delmym#./test_deploy.sh   ####注释了自动部署测试用例的过程
#delmym#/usr/local/qemu_mym/bin/qemu-system-i386   -hda  ../lubuntu/lubuntu12.04.raw   -boot c  -m 2048  -rtc clock=vm -icount shift=7,align=off    -d exec,in_asm -D ../logfifo 
###注释了生成qemu日志的过程

#delmym#采用了输出文件到管道的方法，一个日志可以多次测试
cat ../xxxx.ww  >  ../logfifo
#####以后可以改回来




流水处理  v_top.sh
===============================
1.

for m_file in  ${file_array[@]}
do
echo $m_file

./create_ab.py $log_path/$m_file      #这个过程中能够发现空的块，记录到错误文件empty_block.txt中。不录入*.log.a            
./stata.py < "${m_file}.a" > "${m_file}.a.stat"   ../regptn.txt   
##在regptn.txt中放入了正则表达式列表，在stata.py中对每个指令块进行了正则表达式匹配，并以expptn+i  count的形式进行了，统计汇总
./statb.py < "${m_file}.b" > "b${m_file}.b.stat" 
./hash_a.py   < "${m_file}.a.stat" 
./hash_b.py   < "${m_file}.b.stat"

#mv   $log_path/$m_file $log_done/

#删除  0.log 0.log.a 0.log.b 0.log.a.stat 0.log.b.stat
rm -rf  $log_path/$m_file
rm -rf  ${m_file}.a
rm -rf  ${m_file}.a.stat
rm -rf  ${m_file}.b
rm -rf  ${m_file}.b.stat
done


#输入 0.log 1.log   输出0.log.a 0.log.b 0.log.a.stat 0.log.b.stat
xxx.hsha
xxx.hshb
empty_block.txt




汇总 v_bottom.sh
================================
3.
对b的hash块进行汇总这样就是总的bid,pid,tid的汇总

for m_file in `ls -v   *.hshb`
do
./stat_hash_b.py  <  ${m_file} > ${m_file}.stat

#删除xxxx.hshb
rm -rf ${m_file}
done

#输入xxxx.hshb 输出xxx.hshb.stat





4.
对xxx.hsha,  xxx.hshb.stat哈希块进行连接
形成xxx.join


for m_file in `ls -v  *.hsha`
do
m=${m_file%.*}
./join.py   ${m_file}    ${m}.hshb.stat

rm -rf   ${m_file}   ${m}.hshb.stat
done

sort fa_error.txt |uniq > fa_error_uniq.txt
sort fb_error.txt |uniq > fb_eeror_uniq.txt

输入　xxx.hsha   xxx.hshb.stat 输出 xxx.join   fa_error.txt  fb_error.txt   fa_error_uniq.txt  fb_error_uniq.txt
###在将xxx.hasha读入内存时会输出a中重复定义的块  fa_error.txt 也就是说没有对A进行清洗
##连接的过程中会输出b中使用了但是在a中找不到的块的id, fb_error.txt  如果没有bug是不会出现这种情况的

 
5.
对每个连接好的hash块进行按线程进行统计
for m_file in `ls -v  *.join`
do
./thread_stat.py  < $m_file   > $m_file.subth
rm -rf $m_file
done

输入 xxx.join   输出 xxx.join.subth

6.
对pid 进行哈希MOD FFF40000
对pid,tid在进行hash分组使得分成好多块

for m_file in `ls -v  *.join.subth`
do
./hash_thread.py  < $m_file
rm -rf $m_file
done


输入xxx.join.subth  输出 xxx.hshth


6.1
分块进行汇总
for m_file in `ls -v  *.hshth`
do
./thread_stat.py  < $m_file  > $m_file.thd
done
得到的就是总的线程的统计信息

输入xxx.hshth  输出 xxx.hshth.thd


对hash块进行排序
cat `ls -v *.hshth.thd` | sort  -k 1 -k 2  > v_all_thread.thst 

输入 xxx.hash.thd  输出  v_all_thread.thst



7.
对总的线程信息汇总得到所有的指令频度
./proc_all.py < v_all_thread.thst   > v_all.txt
输入 xxx.hash.thd  输出  v_all.txt


对指令频度进行排序
sort -nr -k 2 v_all.txt  > v_all_sort.txt


9.
生成总的线程指令频度统计html
./gen_thread_table.py  < v_all_thread.thst  > v_all_thread.thst.html normal

生成总的线程正则表达式频度统计html
./gen_thread_table.py  < v_all_thread.thst  > v_exp_all_thread.thst.html exp



8.
生成总的指令频度html
./gen_all_table.py  < v_all_sort.txt  > v_all_sort.html normal

生成总的正则表达式频度html
./gen_all_table.py  < v_all_sort.txt  > v_exp_all_sort.html exp


部署方法：
#############################
mount lubuntu.raw  到./rawmount
1.拷贝test***.sikuli.tar.gz 到固定的目录./rawmount/root/Documents

2.解压
test***.sikuli.tar.gz
获取到test***.sikuli文件夹

3.
从test***.sikuli文件夹中读取testrun.txt
读取其内容到
aaa.sh

#!/bin/bash
rm -rf /root/new/bbb.txt
echo "start" > /root/new/bbb.txt
date >> /root/new/bbb.txt
#####要替换的命令/usr/local/runScript -r /root/Documents/test-ods.sikuli
date >> /root/new/bbb.txt
echo "stop" >> /root/new/bbb.txt
lxterminal &
#shutdown -h now


将执行完的测试用从lubuntu拷贝出来的时候必须知道拷贝哪个文件夹
方法是部署的时候，建立一个同名的文件夹在./test_result目录下
4.
umount rawmount
运行虚拟机进行指令频度统计，完毕后将测试用例所在的文件夹打包拷贝出来，返回给用户
