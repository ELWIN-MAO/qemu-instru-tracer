从经验看a[i].log.stat哈希完以后每个文件100M左右最合适
由于bid pid tid  增加的间隔很不一样，用mod的话，合适的mod值很难找。如果是连续的那用mod出来，
可以很好的控制块数，已经各个块的大小一致。



使用root账号登陆
cd
all_work_flow\prog
./start_all.sh 自动处理所有流程

./v_kill.sh 关掉所有的程序



v_clean.sh 清理中间结果，以及最后结果，只保留程序代码。


流水处理  v_top.sh
===============================
1.对0,1,2,3形成

for m_file in  ${file_array[@]}
do
echo $m_file

./create_ab.py $log_path/$m_file                      
./stata.py < "${m_file}.a" > "${m_file}.a.stat"    
./statb.py < "${m_file}.b" > "b${m_file}.b.stat" 
./hash_a.py   < "${m_file}.a.stat" 
./hash_b.py   < "${m_file}.b.stat"

mv   $log_path/$m_file $log_done/ 
done

sort ./error_opcode.txt  | uniq > error_opcode_uniq.txt

#输入 0.log 1.log   输出a0.log b0.log a0.log.stat b0.log.stat

输入 0.log 1.log   输出0.log.a 0.log.b 0.log.a.stat 0.log.b.stat
xxx.hsha
xxx.hshb
error_opcode.txt
error_opcode_uniq.txt 




汇总 v_bottom.sh
================================
3.
对b的hash块进行汇总这样就是总的bid,pid,tid的汇总

for m_file in `ls -v   *.hshb`
do
./stat_hash_b.py  <  ${m_file} > ${m_file}.stat
done

输入xxxx.hshb 输出xxx.hshb.stat


4.
对xxx.hsha,  xxx.hshb.stat哈希块进行连接
形成xxx.join


for m_file in `ls -v  *.hsha`
do
m=${m_file%.*}
./join.py   ${m_file}    ${m}.hshb.stat
done

sort fa_error.txt |uniq > fa_error_uniq.txt
sort fb_error.txt |uniq > fb_eeror_uniq.txt

输入　xxx.hsha   xxx.hshb.stat 输出 xxx.join   fa_error.txt  fb_error.txt   fa_error_uniq.txt  fb_error_uniq.txt
###在将xxx.hasha读入内存时会输出a中重复定义的块  fa_error.txt 也就是说没有对A进行清洗
##连接的过程中会输出b中使用了但是在a中找不到的块的id, fb_error.txt  如果没有bug是不会出现这种情况的
 
5.
对每个连接好的hash块进行按线程进行统计
for m_file in `ls -v  *.join`
do
./thread_stat.py  < $m_file   > $m_file.subth
done

输入 xxx.join   输出 xxx.join.subth

6.
对pid 进行哈希MOD FFF40000
对pid,tid在进行hash分组使得分成好多块

for m_file in `ls -v  *.join.subth`
do
./hash_thread.py  < $m_file
done


输入xxx.join.subth  输出 xxx.hshth


6.1
分块进行汇总
for m_file in `ls -v  *.hshth`
do
./thread_stat.py  < $m_file  > $m_file.thd
done
得到的就是总的线程的统计信息

输入xxx.hshth  输出 xxx.hshth.thd


对hash块进行排序
cat `ls -v *.hshth.thd` | sort  -k 1 -k 2  > v_all_thread.thst 

输入 xxx.hash.thd  输出  v_all_thread.thst



7.
对总的线程信息汇总得到所有的指令频度
./proc_all.py < v_all_thread.thst   > v_all.txt
输入 xxx.hash.thd  输出  v_all.txt


对指令频度进行排序
sort -nr -k 2 v_all.txt  > v_all_sort.txt


9.
生成总的线程指令频度统计html
./gen_thread_table.py  < v_all_thread.thst  > v_all_thread.thst.html

8.
生成总的指令频度html
./gen_all_table.py  < v_all_sort.txt  > v_all_sort.html




