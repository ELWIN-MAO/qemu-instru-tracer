从经验看a[i].log.stat哈希完以后每个文件100M左右最合适
由于bid pid tid  增加的间隔很不一样，用mod的话，合适的mod值很难找。如果是连续的那用mod出来，
可以很好的控制块数，已经各个块的大小一致。



v_clean.sh 清理中间结果，以及最后结果。


流水处理  v_top.sh
===============================
1.对0,1,2,3形成

for m_file in  ${file_array[@]}
do
echo $m_file

./create_ab.py $log_path/$m_file
./stata.py < "a${m_file}" > "a${m_file}.stat"
./statb.py < "b${m_file}" > "b${m_file}.stat"
./hash_a.py   < "a${m_file}.stat"
./hash_b.py   < "b${m_file}.stat"

mv   $log_path/$m_file $log_done/
done

输入 0.log 1.log   输出a0.log b0.log a0.log.stat b0.log.stat


汇总 v_bottom.sh
================================
3.
对b的hash块进行汇总这样就是总的bid,pid,tid的汇总

for m_file in `ls -v   *.b`
do
./stat_hash_b.py  <  ${m_file} > ${m_file}.stat
done

输入xxxx.b 输出xxx.b.stat


这样也没法剔除出在b[i].stat中有定义，但是在a中没有定义的块。
因为block_id是跳跃的。


4.
对xxx.a,  xxx.b.stat哈希块进行连接
形成xxx.join
连接的过程中会输出
(b中使用了但是在a中找不到的块的id）,如果没有bug是不会出现这种情况的。错误文件fbe.txt追加写入
a中重复定义的块  faerror.txt 也就是说没有对A进行清洗

for m_file in `ls -v  *.a`
do
m=${m_file%.*}
./join.py   ${m_file}    ${m}.b.stat
done

输入　xxx.a   xxx.b.stat 输出 xxx.join

5.
对每个连接好的hash块进行按线程进行统计
for m_file in `ls -v  *.join`
do
./thread_stat.py  < $m_file   > $m_file.subth
done

输入 xxx.join   输出 xxx.join.subth

6.
对pid 进行哈希MOD FFF40000
对pid,tid在进行hash分组使得分成好多块

for m_file in `ls -v  *.join.subth`
do
./hash_thread.py  < $m_file
done


输入xxx.join.subth  输出 xxx.hash


6.1
分块进行汇总
for m_file in `ls -v  *.hash`
do
./thread_stat.py  < $m_file  > $m_file.thd
done
得到的就是总的线程的统计信息

输入xxx.hash  输出 xxx.hash.thd

7.
对总的线程信息汇总得到所有的指令频度
for m_file in `ls -v  *.hash.thd`
do
./proc_all.py  < $m_file  > v_all.txt
done

输入 xxx.hash.thd  输出  v_all.txt


缺少生成html文档过程
=================================================




